{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AstNet inference code for EMA Time-Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries and setup matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "import IPython.display as ipd\n",
    "\n",
    "import sys\n",
    "sys.path.append('waveglow/')\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from hparams import create_hparams\n",
    "from model import Tacotron2\n",
    "from layers import TacotronSTFT, STFT\n",
    "from audio_processing import griffin_lim\n",
    "from train import load_model\n",
    "\n",
    "#my libraries\n",
    "import scipy.io as sio\n",
    "from phoneme_to_seq import *\n",
    "from fastdtw import fastdtw\n",
    "import random\n",
    "from scipy.spatial.distance import euclidean\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, figsize=(16, 4)):\n",
    "    fig, axes = plt.subplots(1, len(data), figsize=figsize)\n",
    "    for i in range(len(data)):\n",
    "        axes[i].imshow(data[i], aspect='auto', origin='bottom', \n",
    "                       interpolation='none')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = create_hparams()\n",
    "hparams.sampling_rate = 22050\n",
    "hparams.max_decoder_steps=1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"checkpoint page\"\n",
    "print(\"loading: \\n\",checkpoint_path)\n",
    "model = load_model(hparams)\n",
    "model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "\n",
    "_ = model.cuda().eval().half()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_arr=np.zeros((4,5,115))\n",
    "lengths=np.zeros((4,5,2,115))\n",
    "Big_C=np.zeros((4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inference over all subjects\n",
    "predictions={}\n",
    "for f_no in range(1,5):\n",
    "    dd=[];\n",
    "    sub_list=[] # subject list\n",
    "    for sub in sub_list:\n",
    "        if f_no==1:\n",
    "            predictions[sub]={}\n",
    "        checkpoint_path = \"\" # respective subject checkpoint path\n",
    "        print(\"loading: \\n\",checkpoint_path)\n",
    "        model = load_model(hparams)\n",
    "        model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
    "        _ = model.cuda().eval().half()\n",
    "\n",
    "        print(sub)\n",
    "        test_file= open(\"path to test filelist\",'r')\n",
    "        print(\"Testin on : \",test_file.name)\n",
    "        lines=test_file.readlines()\n",
    "        coefficients=[]\n",
    "        rMSE=[]\n",
    "        dist=[]\n",
    "        for line in lines:\n",
    "            path=line.split('|')\n",
    "            sequence = np.expand_dims(clip_ema_silence(path[1][:-1]),axis=0)\n",
    "            #print(sequence.shape)\n",
    "            sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().half()\n",
    "\n",
    "            ##### Decode text input and plot results\n",
    "\n",
    "            torch.manual_seed(1234)\n",
    "            mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence.transpose(1,2))\n",
    "            X=clip_ema_silence(path[0])\n",
    "            Y=mel_outputs[0].cpu().detach().numpy().transpose()\n",
    "            #storing predictions\n",
    "            predictions[sub][str(lines.index(line)+(f_no-1)*115)]=Y\n",
    "            ##lengths of gt and predicted sequences\n",
    "            lengths[f_no-1][sub_list.index(sub)][0][lines.index(line)]=X.shape[0]\n",
    "            lengths[f_no-1][sub_list.index(sub)][1][lines.index(line)]=Y.shape[0]\n",
    "            #print(X.shape,Y.shape)\n",
    "            dis,pth=fastdtw(X,Y, dist=euclidean)\n",
    "            dist.append(dis/len(pth))\n",
    "            for artic in range(0,18):\n",
    "                out=[]\n",
    "                gt=[]\n",
    "                for i in range(0,len(pth)):\n",
    "                    out.append(Y[pth[i][1]][artic])\n",
    "                    #for i in range(0,Yout.shape[0]):\n",
    "                    gt.append(X[pth[i][0]][artic])\n",
    "                coef=pearsonr(out,gt)\n",
    "                coefficients.append(coef)\n",
    "                rMSE.append(np.sqrt(np.mean(np.square(np.asarray(out)-np.asarray(gt)))))\n",
    "        Big_C[f_no-1][sub_list.index(sub)]=np.mean(coefficients,axis=0)[0]\n",
    "        dist_arr[f_no-1][sub_list.index(sub)]=np.asarray(dist)\n",
    "        print('RMSE : ',np.mean(rMSE,axis=0))      \n",
    "        print('CC : ',np.mean(coefficients,axis=0))\n",
    "        print('DTW_distance : ',np.mean(dist,axis=0))\n",
    "        dd.append(np.mean(dist,axis=0))\n",
    "    print(np.mean(np.asarray(dd)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Big_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions['Advith'].keys()\n",
    "#sio.savemat('predictions_n2f.mat',{\"predictions\":predictions})\n",
    "#import pickle\n",
    "with open('pred_n2f.pickle','wb') as hdl:\n",
    "    pickle.dump(predictions,hdl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,a=plt.subplots(1,2)\n",
    "print(a)\n",
    "a[0].hist(lengths[0][0][0])\n",
    "a[0].set_title(\"Ground-Truth\")\n",
    "a[1].hist(lengths[0][0][1],20)\n",
    "a[1].set_title(\"Predicted\")\n",
    "plt.savefig('hist_fold1_n2s.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get standard deviation and saving dtw distances\n",
    "sio.savemat(\"N2F_pool_36500.mat\",{\"data\":dist_arr})\n",
    "np.mean(dist_arr,axis=-1)\n",
    "np.std(dist_arr,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode text input and plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c=np.asarray(coefficients)\n",
    "c=c[:,0].reshape(575,18)\n",
    "c=np.mean(c,axis=0)\n",
    "print(\"Correlation : \\n\",c)\n",
    "rmse=np.asarray(rMSE)\n",
    "rmse=rmse[:].reshape(575,18)\n",
    "rmse=np.mean(rmse,axis=0)\n",
    "print(\"RMSE : \\n\", rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##write xlsx\n",
    "import xlsxwriter\n",
    "workbk=xlsxwriter.Workbook('excel_sheets/results_'+sub_list[sub]+'.xlsx')\n",
    "wrksht=workbk.add_worksheet()\n",
    "print(\"Writing to \",'excel_sheets/results_'+sub_list[sub]+'.xlsx')\n",
    "row=0\n",
    "col=0\n",
    "for x,y,i in zip(c,rmse,range(0,12)):\n",
    "    wrksht.write(row,col,x)\n",
    "    wrksht.write(row+5,col,y)\n",
    "    col+=1\n",
    "workbk.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Best Articulatory Plots</h3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffi=[]\n",
    "path=lines[int(coefficients.index(min(coefficients))/18)].split('|')\n",
    "sequence = np.expand_dims(clip_ema_silence(path[1][:-1]),axis=0)\n",
    "print(sequence.shape)\n",
    "sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().half()\n",
    "##### Decode text input and plot results\n",
    "torch.manual_seed(1234)\n",
    "mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence.transpose(1,2))\n",
    "#####plot with ema gt\n",
    "####plot with dtw aligned and correlation\n",
    "X=clip_ema_silence(path[0])\n",
    "Y=mel_outputs[0].cpu().detach().numpy().transpose()\n",
    "dis,pth=fastdtw(X,Y, dist=euclidean)\n",
    "for artic in range(0,18):\n",
    "    out=[]\n",
    "    gt=[]\n",
    "    for i in range(0,len(pth)):\n",
    "        out.append(Y[pth[i][1]][artic])\n",
    "        #for i in range(0,Yout.shape[0]):\n",
    "        gt.append(X[pth[i][0]][artic])\n",
    "    coef=pearsonr(out,gt)\n",
    "    coeffi.append(coef)\n",
    "    plt.plot(gt)\n",
    "    plt.plot(out)\n",
    "    plt.figure()\n",
    "print(coeffi[coefficients.index(max(coefficients))%12])\n",
    "print(np.mean(coeffi,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Alignment for sentence</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dct=prep_dct()\n",
    "path='../RateExp/Advith/Neutral/EmaClean/s001Nl01m0001.mat'\n",
    "sequence = np.expand_dims(clip_ema_silence(path),axis=0)\n",
    "print(sequence.shape)\n",
    "sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().half()\n",
    "\n",
    "##### Decode text input and plot results\n",
    "\n",
    "torch.manual_seed(1234)\n",
    "mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence.transpose(1,2))\n",
    "print(sequence.shape)\n",
    "print(alignments.shape)\n",
    "plot_data((mel_outputs.float().data.cpu().numpy()[0],\n",
    "           mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
    "           alignments.float().data.cpu().numpy()[0].T))\n",
    "import scipy.io as sio\n",
    "sio.savemat('alignment_slow.mat',{'align':alignments.float().data.cpu().numpy()[0].T})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
